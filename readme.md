## Thanks for your help !!!
## 感谢你的帮助！！！

### 步骤 steps
1. git clone
2. pip install -r requirements.txt
3. download selenium extension and place it to python path
4. select the ids you help
5. run crawl.py



### 注意
如果你准备或已经运行了部分数据的爬虫，请将对应的id告知我或通过issue提交，避免重复采集，谢谢你的帮助！